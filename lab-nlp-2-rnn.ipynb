{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2730445,"sourceType":"datasetVersion","datasetId":1167113}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Подключим необходимые пакеты","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\n\nfrom datasets import load_dataset\nfrom nltk.tokenize import sent_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\n\nfrom collections import Counter\nfrom typing import List\nfrom tqdm import tqdm\n\nimport seaborn\nseaborn.set(palette='summer')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T06:36:58.562538Z","iopub.execute_input":"2024-05-27T06:36:58.562902Z","iopub.status.idle":"2024-05-27T06:37:05.144386Z","shell.execute_reply.started":"2024-05-27T06:36:58.562864Z","shell.execute_reply":"2024-05-27T06:37:05.143330Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:05.146258Z","iopub.execute_input":"2024-05-27T06:37:05.146911Z","iopub.status.idle":"2024-05-27T06:37:05.177414Z","shell.execute_reply.started":"2024-05-27T06:37:05.146875Z","shell.execute_reply":"2024-05-27T06:37:05.176534Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Загрузим данные","metadata":{}},{"cell_type":"code","source":"conn = sqlite3.connect('/kaggle/input/wikibooks-dataset/wikibooks.sqlite')\n\ndf = pd.read_sql_query(\"SELECT * FROM ru LIMIT 3300\", conn)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:05.178683Z","iopub.execute_input":"2024-05-27T06:37:05.178981Z","iopub.status.idle":"2024-05-27T06:37:07.460813Z","shell.execute_reply.started":"2024-05-27T06:37:05.178956Z","shell.execute_reply":"2024-05-27T06:37:07.459789Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"sentences = []\n\nfor sentence in tqdm(df['body_text']):\n    sentences.extend(\n        [x.lower() for x in sent_tokenize(sentence, language='russian') if len(x) < 256]\n        )\n    \nprint(\"Количество предложений\", len(sentences))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:07.462919Z","iopub.execute_input":"2024-05-27T06:37:07.463212Z","iopub.status.idle":"2024-05-27T06:37:18.321971Z","shell.execute_reply.started":"2024-05-27T06:37:07.463187Z","shell.execute_reply":"2024-05-27T06:37:18.321047Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 3300/3300 [00:10<00:00, 304.16it/s]","output_type":"stream"},{"name":"stdout","text":"Количество предложений 120873\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer, sheduler = None):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n    losses = []\n    perplexity = []\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        logits = model(batch['input_ids']).flatten(start_dim=0, end_dim=1)\n        loss = criterion(\n            logits, batch['target_ids'].flatten())\n        loss.backward()\n        optimizer.step()\n        \n        perplexity.append(torch.exp(loss).item())\n        losses.append(loss.item())\n        \n    perplexity = sum(perplexity) / len(perplexity)\n    losses = sum(losses) / len(losses)    \n    return perplexity, losses\n\n\n\ndef eval_epoch(model, val_loader, criterion):\n    model.eval()\n    perplexity = []\n    losses = []\n    with torch.no_grad():\n        for batch in val_loader:\n            logits = model(batch['input_ids']).flatten(start_dim=0, end_dim=1)\n            loss = criterion(\n                logits,\n                batch['target_ids'].flatten()\n                )\n            perplexity.append(torch.exp(loss).item())\n            losses.append(loss.item())\n\n    perplexity = sum(perplexity) / len(perplexity)\n    losses = sum(losses) / len(losses)\n    return perplexity, losses\n\n\n\ndef train(train_dataloader, eval_dataloader, model, epochs, ignore_index = char2ind['<pad>'] ,\n          optimizer=None, criterion=None, sheduler=None):\n\n    if optimizer is None:\n      optimizer = torch.optim.Adam(model.parameters())\n\n    if criterion is None:\n      criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n\n    best_model_wts = model.state_dict()\n    best_perplexity = 10e10\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_perplexirty {t_acc:0.4f} val_perplexirty {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n\n        for epoch in range(epochs):\n            train_perplexirty, train_loss = fit_epoch(model, train_dataloader, criterion, optimizer)\n\n            val_perplexirty, val_loss = eval_epoch(model, eval_dataloader, criterion)\n            history.append((train_loss, train_perplexirty, val_loss, val_perplexirty))\n            if val_perplexirty < best_perplexity:\n                best_perplexity = val_perplexirty\n                best_model_wts = model.state_dict()\n\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_perplexirty, v_acc=val_perplexirty))\n\n    print('Best val perplexirty: {:4f}'.format(best_perplexity))\n    model.load_state_dict(best_model_wts)\n\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:07:00.856448Z","iopub.execute_input":"2024-05-27T07:07:00.857074Z","iopub.status.idle":"2024-05-27T07:07:00.872381Z","shell.execute_reply.started":"2024-05-27T07:07:00.857045Z","shell.execute_reply":"2024-05-27T07:07:00.871239Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Посимвольная токенизация","metadata":{}},{"cell_type":"code","source":"stop_chars = [\"\\t\", \",\", \".\", \"!\", \"@\", \"'\", '\"', \";\", \"\\n\", \"(\", \")\",\n             \"[\", \"]\", \"{\", \"}\", \"?\", \":\", \"-\", \"_\", \"+\", \"=\", \"^\", \"*\", \n              \"&\", \"`\", \"~\"]\n\nchars = Counter()\n\nfor sentence in tqdm(sentences):\n    for char in sentence:\n        if char in stop_chars:\n            continue\n        chars[char] += 1\n        \nvocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\ncounter_threshold = 500\n\nfor char, cnt in chars.items():\n    if cnt > counter_threshold:\n        vocab.add(char)\n        \nprint(\"Размер словаря:\", len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:18.342290Z","iopub.execute_input":"2024-05-27T06:37:18.342608Z","iopub.status.idle":"2024-05-27T06:37:27.770602Z","shell.execute_reply.started":"2024-05-27T06:37:18.342583Z","shell.execute_reply":"2024-05-27T06:37:27.769748Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 120873/120873 [00:09<00:00, 12853.64it/s]","output_type":"stream"},{"name":"stdout","text":"Размер словаря: 91\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"char2ind = {char: i for i, char in enumerate(vocab)}\nind2char = {i: char for char, i in char2ind.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:27.771635Z","iopub.execute_input":"2024-05-27T06:37:27.771882Z","iopub.status.idle":"2024-05-27T06:37:27.776457Z","shell.execute_reply.started":"2024-05-27T06:37:27.771860Z","shell.execute_reply":"2024-05-27T06:37:27.775608Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class CharDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = char2ind['<unk>']\n        self.bos_id = char2ind['<bos>']\n        self.eos_id = char2ind['<eos>']\n        self.pad_id = char2ind['<pad>']\n\n    def __getitem__(self, idx: int) -> List[int]:\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [char2ind.get(char, self.unk_id) for char in self.data[idx]]\n        tokenized_sentence += [self.eos_id]\n\n        return tokenized_sentence\n\n    def __len__(self) -> int:\n        return len(self.data)\n    \n    \nclass WordDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = word2ind['<unk>']\n        self.bos_id = word2ind['<bos>']\n        self.eos_id = word2ind['<eos>']\n        self.pad_id = word2ind['<pad>']\n\n    def __getitem__(self, idx: int) -> List[int]:\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [word2ind.get(word, self.unk_id) for word in nltk.word_tokenize(self.data[idx])]\n        tokenized_sentence += [self.eos_id]\n        \n        return tokenized_sentence\n\n    def __len__(self) -> int:\n        return len(self.data)\n    \n    \n    \ndef collate_fn_with_padding(\n    input_batch: List[List[int]], pad_id=char2ind['<pad>']) -> torch.Tensor:\n    seq_lens = [len(x) for x in input_batch]\n    max_seq_len = max(seq_lens)\n\n    new_batch = []\n    for sequence in input_batch:\n        for _ in range(max_seq_len - len(sequence)):\n            sequence.append(pad_id)\n        new_batch.append(sequence)\n\n    sequences = torch.LongTensor(new_batch).to(device)\n\n    new_batch = {\n        'input_ids': sequences[:,:-1],\n        'target_ids': sequences[:,1:]\n    }\n\n    return new_batch\n\n\ndef generate_sequence(model, dict_2ind ,ind2dict, starting_seq: str, max_seq_len: int = 256) -> str:\n    device = 'cpu'\n    model = model.to(device)\n    input_ids = [dict_2ind['<bos>']] + [\n        dict_2ind.get(char, dict_2ind['<unk>']) for char in starting_seq]\n    input_ids = torch.LongTensor(input_ids).to(device)\n\n    model.eval()\n    with torch.no_grad():\n        for i in range(max_seq_len):\n            next_char_distribution = model(input_ids)[-1]\n            next_char = next_char_distribution.squeeze().argmax()\n            input_ids = torch.cat([input_ids, next_char.unsqueeze(0)])\n\n            if next_char.item() == dict_2ind['<eos>']:\n                break\n\n    words = ' '.join([ind2dict[idx.item()] for idx in input_ids])\n\n    return words","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:34:40.612223Z","iopub.execute_input":"2024-05-27T07:34:40.613111Z","iopub.status.idle":"2024-05-27T07:34:40.634068Z","shell.execute_reply.started":"2024-05-27T07:34:40.613080Z","shell.execute_reply":"2024-05-27T07:34:40.633131Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Разобьём датасет на train и eval, так же определим dataloader для train и eval","metadata":{}},{"cell_type":"code","source":"train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\n\ntrain_dataset = CharDataset(train_sentences)\neval_dataset = CharDataset(eval_sentences)\n\ntrain_dataloader = DataLoader(\n    train_dataset, collate_fn=collate_fn_with_padding, batch_size=256)\n\neval_dataloader = DataLoader(\n    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:27.796208Z","iopub.execute_input":"2024-05-27T06:37:27.796506Z","iopub.status.idle":"2024-05-27T06:37:27.849056Z","shell.execute_reply.started":"2024-05-27T06:37:27.796481Z","shell.execute_reply":"2024-05-27T06:37:27.848052Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Определим архитектуру на основе LSTM","metadata":{}},{"cell_type":"code","source":"class LanguageModel(nn.Module):\n    def __init__(self, vocab_size, hidden_dim, num_layers = 1):\n        super().__init__()\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n        self.lstm_layers = nn.ModuleList()\n        for _ in range(num_layers):\n            self.lstm_layers.append(nn.LSTM(hidden_dim, hidden_dim, batch_first=True))\n            \n        self.linear = nn.Linear(hidden_dim, hidden_dim)\n        self.projection = nn.Linear(hidden_dim, vocab_size)\n\n        self.non_lin = nn.Tanh()\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, input_batch: torch.Tensor) -> torch.Tensor:\n        embeddings = self.embedding(input_batch)  # [batch_size, seq_len, hidden_dim]\n        output, _ = self.lstm_layers[0](embeddings)\n        for i in range(1, self.num_layers):\n            output1, _ = self.lstm_layers[i](output)\n            output = output1 + output\n        output = self.dropout(self.linear(self.non_lin(output)))  # [batch_size, seq_len, hidden_dim]\n        projection = self.projection(self.non_lin(output))  # [batch_size, seq_len, vocab_size]\n\n        return projection","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:27.852614Z","iopub.execute_input":"2024-05-27T06:37:27.852914Z","iopub.status.idle":"2024-05-27T06:37:27.862441Z","shell.execute_reply.started":"2024-05-27T06:37:27.852888Z","shell.execute_reply":"2024-05-27T06:37:27.861140Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = LanguageModel(hidden_dim=256, vocab_size=len(vocab), num_layers = 1).to(device)\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:27.863702Z","iopub.execute_input":"2024-05-27T06:37:27.864021Z","iopub.status.idle":"2024-05-27T06:37:28.189928Z","shell.execute_reply.started":"2024-05-27T06:37:27.863994Z","shell.execute_reply":"2024-05-27T06:37:28.189176Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"LanguageModel(\n  (embedding): Embedding(91, 256)\n  (lstm_layers): ModuleList(\n    (0): LSTM(256, 256, batch_first=True)\n  )\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=91, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.2, inplace=False)\n)\nNumber of model parameters: 638,811\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model, history = train(train_dataloader, eval_dataloader, model, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:37:28.191133Z","iopub.execute_input":"2024-05-27T06:37:28.191820Z","iopub.status.idle":"2024-05-27T06:43:52.518872Z","shell.execute_reply.started":"2024-05-27T06:37:28.191784Z","shell.execute_reply":"2024-05-27T06:43:52.517969Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [00:38<05:50, 38.95s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 2.2684     val_loss 1.8093 train_perplexirty 11.2871 val_perplexirty 6.1087\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [01:17<05:07, 38.45s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 1.7334     val_loss 1.6459 train_perplexirty 5.6688 val_perplexirty 5.1875\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [01:55<04:27, 38.28s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 1.6260     val_loss 1.5770 train_perplexirty 5.0863 val_perplexirty 4.8421\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [02:33<03:49, 38.22s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 1.5694     val_loss 1.5345 train_perplexirty 4.8059 val_perplexirty 4.6406\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [03:11<03:10, 38.20s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 1.5308     val_loss 1.5051 train_perplexirty 4.6237 val_perplexirty 4.5061\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [03:49<02:32, 38.20s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 1.5025     val_loss 1.4830 train_perplexirty 4.4945 val_perplexirty 4.4075\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [04:27<01:54, 38.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 1.4809     val_loss 1.4653 train_perplexirty 4.3984 val_perplexirty 4.3302\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [05:05<01:16, 38.17s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 1.4633     val_loss 1.4515 train_perplexirty 4.3217 val_perplexirty 4.2709\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [05:44<00:38, 38.16s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 1.4493     val_loss 1.4402 train_perplexirty 4.2615 val_perplexirty 4.2231\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [06:22<00:00, 38.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 1.4380     val_loss 1.4309 train_perplexirty 4.2135 val_perplexirty 4.1838\nBest val perplexirty: 4.183791\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_sequence(model, char2ind, ind2char, starting_seq='источник связан с ')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:46:00.844880Z","iopub.execute_input":"2024-05-27T06:46:00.845616Z","iopub.status.idle":"2024-05-27T06:46:01.729564Z","shell.execute_reply.started":"2024-05-27T06:46:00.845583Z","shell.execute_reply":"2024-05-27T06:46:01.728627Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'<bos>источник связан с помощью программы в соответствии с помощью программы в соответствии с помощью программы в соответствии с помощью программы в соответствии с помощью программы в соответствии с помощью программы в соответствии с помощью программы в соответствии с помощью про'"},"metadata":{}}]},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:46:06.226609Z","iopub.execute_input":"2024-05-27T06:46:06.226967Z","iopub.status.idle":"2024-05-27T06:46:06.479716Z","shell.execute_reply.started":"2024-05-27T06:46:06.226936Z","shell.execute_reply":"2024-05-27T06:46:06.478708Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"186"},"metadata":{}}]},{"cell_type":"markdown","source":"### Теперь добавим несколько слоев LSTM","metadata":{}},{"cell_type":"code","source":"model = LanguageModel(hidden_dim=256, vocab_size=len(vocab), num_layers = 3).to(device)\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:46:09.497536Z","iopub.execute_input":"2024-05-27T06:46:09.497892Z","iopub.status.idle":"2024-05-27T06:46:09.526138Z","shell.execute_reply.started":"2024-05-27T06:46:09.497862Z","shell.execute_reply":"2024-05-27T06:46:09.525213Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"LanguageModel(\n  (embedding): Embedding(91, 256)\n  (lstm_layers): ModuleList(\n    (0-2): 3 x LSTM(256, 256, batch_first=True)\n  )\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=91, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.2, inplace=False)\n)\nNumber of model parameters: 1,691,483\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model, history = train(train_dataloader, eval_dataloader, model, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:46:16.293180Z","iopub.execute_input":"2024-05-27T06:46:16.294451Z","iopub.status.idle":"2024-05-27T07:00:04.570622Z","shell.execute_reply.started":"2024-05-27T06:46:16.294418Z","shell.execute_reply":"2024-05-27T07:00:04.569742Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [01:23<12:30, 83.39s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 2.1932     val_loss 1.7179 train_perplexirty 10.6381 val_perplexirty 5.5749\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [02:46<11:07, 83.39s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 1.6379     val_loss 1.5451 train_perplexirty 5.1536 val_perplexirty 4.6904\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [04:10<09:43, 83.35s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 1.5146     val_loss 1.4654 train_perplexirty 4.5507 val_perplexirty 4.3308\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [05:33<08:19, 83.29s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 1.4459     val_loss 1.4181 train_perplexirty 4.2476 val_perplexirty 4.1307\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [06:55<06:55, 83.05s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 1.4003     val_loss 1.3854 train_perplexirty 4.0579 val_perplexirty 3.9980\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [08:18<05:31, 82.84s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 1.3662     val_loss 1.3589 train_perplexirty 3.9220 val_perplexirty 3.8935\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [09:40<04:08, 82.76s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 1.3392     val_loss 1.3394 train_perplexirty 3.8173 val_perplexirty 3.8179\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [11:03<02:45, 82.71s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 1.3167     val_loss 1.3255 train_perplexirty 3.7324 val_perplexirty 3.7654\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [12:25<01:22, 82.61s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 1.2982     val_loss 1.3158 train_perplexirty 3.6638 val_perplexirty 3.7291\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [13:48<00:00, 82.83s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 1.2819     val_loss 1.3065 train_perplexirty 3.6046 val_perplexirty 3.6946\nBest val perplexirty: 3.694581\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_sequence(model, char2ind, ind2char, starting_seq='источник связан с ')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:03:43.168233Z","iopub.execute_input":"2024-05-27T07:03:43.168601Z","iopub.status.idle":"2024-05-27T07:03:43.280747Z","shell.execute_reply.started":"2024-05-27T07:03:43.168574Z","shell.execute_reply":"2024-05-27T07:03:43.279744Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'<bos>источник связан с помощью статьи по проекту<unk><eos>'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Пословная токенизация","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:05:57.710467Z","iopub.execute_input":"2024-05-27T07:05:57.710851Z","iopub.status.idle":"2024-05-27T07:05:58.006463Z","shell.execute_reply.started":"2024-05-27T07:05:57.710820Z","shell.execute_reply":"2024-05-27T07:05:58.005630Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"485"},"metadata":{}}]},{"cell_type":"code","source":"words = Counter()\n\nfor sentence in tqdm(sentences):\n    for word in nltk.word_tokenize(sentence):\n            words[word] += 1\n            \nvocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\nvocab_size = 40000\n\nfor elem in words.most_common(vocab_size):\n    vocab.add(elem[0])\n    \nprint(\"Всего слов в словаре:\", len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:05:58.888165Z","iopub.execute_input":"2024-05-27T07:05:58.888801Z","iopub.status.idle":"2024-05-27T07:06:28.521820Z","shell.execute_reply.started":"2024-05-27T07:05:58.888770Z","shell.execute_reply":"2024-05-27T07:06:28.520814Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"100%|██████████| 120873/120873 [00:29<00:00, 4096.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Всего слов в словаре: 40004\n","output_type":"stream"}]},{"cell_type":"code","source":"word2ind = {char: i for i, char in enumerate(vocab)}\nind2word = {i: char for char, i in word2ind.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:06:28.611988Z","iopub.execute_input":"2024-05-27T07:06:28.612275Z","iopub.status.idle":"2024-05-27T07:06:28.636012Z","shell.execute_reply.started":"2024-05-27T07:06:28.612250Z","shell.execute_reply":"2024-05-27T07:06:28.634985Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def collate_fn_with_padding(\n    input_batch: List[List[int]], pad_id=word2ind['<pad>']) -> torch.Tensor:\n    seq_lens = [len(x) for x in input_batch]\n    max_seq_len = max(seq_lens)\n\n    new_batch = []\n    for sequence in input_batch:\n        for _ in range(max_seq_len - len(sequence)):\n            sequence.append(pad_id)\n        new_batch.append(sequence)\n\n    sequences = torch.LongTensor(new_batch).to(device)\n\n    new_batch = {\n        'input_ids': sequences[:,:-1],\n        'target_ids': sequences[:,1:]\n    }\n\n    return new_batch","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:15:42.169941Z","iopub.execute_input":"2024-05-27T07:15:42.170640Z","iopub.status.idle":"2024-05-27T07:15:42.177143Z","shell.execute_reply.started":"2024-05-27T07:15:42.170608Z","shell.execute_reply":"2024-05-27T07:15:42.176132Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\n\ntrain_dataset = WordDataset(train_sentences)\neval_dataset = WordDataset(eval_sentences)\n\ntrain_dataloader = DataLoader(\n    train_dataset, collate_fn=collate_fn_with_padding, batch_size=64,)\n\neval_dataloader = DataLoader(\n    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:15:43.172241Z","iopub.execute_input":"2024-05-27T07:15:43.173055Z","iopub.status.idle":"2024-05-27T07:15:43.217030Z","shell.execute_reply.started":"2024-05-27T07:15:43.173027Z","shell.execute_reply":"2024-05-27T07:15:43.216288Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model = LanguageModel(hidden_dim=256, vocab_size=len(vocab), num_layers = 1).to(device)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:15:43.419274Z","iopub.execute_input":"2024-05-27T07:15:43.419634Z","iopub.status.idle":"2024-05-27T07:15:43.660737Z","shell.execute_reply.started":"2024-05-27T07:15:43.419607Z","shell.execute_reply":"2024-05-27T07:15:43.659768Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"LanguageModel(\n  (embedding): Embedding(40004, 256)\n  (lstm_layers): ModuleList(\n    (0): LSTM(256, 256, batch_first=True)\n  )\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=40004, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.2, inplace=False)\n)\nNumber of model parameters: 21,114,180\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model, losses = train(train_dataloader, eval_dataloader, model, 10, ignore_index = word2ind[\"<pad>\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:15:43.858978Z","iopub.execute_input":"2024-05-27T07:15:43.859264Z","iopub.status.idle":"2024-05-27T07:33:41.519490Z","shell.execute_reply.started":"2024-05-27T07:15:43.859240Z","shell.execute_reply":"2024-05-27T07:33:41.518530Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [01:47<16:04, 107.18s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 6.3350     val_loss 5.8254 train_perplexirty 832.8000 val_perplexirty 343.8051\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [03:34<14:17, 107.14s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 5.5044     val_loss 5.4580 train_perplexirty 251.8205 val_perplexirty 238.4559\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [05:21<12:31, 107.35s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 5.0642     val_loss 5.2847 train_perplexirty 161.3904 val_perplexirty 200.8015\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [07:08<10:43, 107.23s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 4.7353     val_loss 5.2213 train_perplexirty 115.9214 val_perplexirty 188.8237\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [08:57<08:57, 107.55s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 4.4719     val_loss 5.2141 train_perplexirty 88.9743 val_perplexirty 187.8421\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [10:45<07:11, 107.88s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 4.2506     val_loss 5.2342 train_perplexirty 71.2702 val_perplexirty 192.0732\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [12:33<05:23, 107.84s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 4.0567     val_loss 5.2870 train_perplexirty 58.7072 val_perplexirty 202.8684\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [14:21<03:35, 107.90s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 3.8872     val_loss 5.3552 train_perplexirty 49.5441 val_perplexirty 217.7147\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [16:09<01:47, 107.99s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 3.7329     val_loss 5.4208 train_perplexirty 42.4665 val_perplexirty 232.9360\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [17:57<00:00, 107.77s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 3.5940     val_loss 5.4889 train_perplexirty 36.9549 val_perplexirty 249.8979\nBest val perplexirty: 187.842122\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_sequence(model, word2ind, ind2word,starting_seq=nltk.word_tokenize('история россии'))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:36:30.214856Z","iopub.execute_input":"2024-05-27T07:36:30.215482Z","iopub.status.idle":"2024-05-27T07:36:30.290692Z","shell.execute_reply.started":"2024-05-27T07:36:30.215453Z","shell.execute_reply":"2024-05-27T07:36:30.289709Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"'<bos> история россии – это наука о росте народонаселения . <eos>'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Добавим несколько слоев LSTM","metadata":{}},{"cell_type":"code","source":"torch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:36:39.118961Z","iopub.execute_input":"2024-05-27T07:36:39.119338Z","iopub.status.idle":"2024-05-27T07:36:39.443342Z","shell.execute_reply.started":"2024-05-27T07:36:39.119288Z","shell.execute_reply":"2024-05-27T07:36:39.442335Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"1995"},"metadata":{}}]},{"cell_type":"code","source":"model = LanguageModel(hidden_dim=256, vocab_size=len(vocab), num_layers = 3).to(device)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:36:48.130088Z","iopub.execute_input":"2024-05-27T07:36:48.130518Z","iopub.status.idle":"2024-05-27T07:36:48.422435Z","shell.execute_reply.started":"2024-05-27T07:36:48.130484Z","shell.execute_reply":"2024-05-27T07:36:48.421464Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"LanguageModel(\n  (embedding): Embedding(40004, 256)\n  (lstm_layers): ModuleList(\n    (0-2): 3 x LSTM(256, 256, batch_first=True)\n  )\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=40004, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.2, inplace=False)\n)\nNumber of model parameters: 22,166,852\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model, losses = train(train_dataloader, eval_dataloader, model, 10, ignore_index = word2ind[\"<pad>\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:36:48.423868Z","iopub.execute_input":"2024-05-27T07:36:48.424165Z","iopub.status.idle":"2024-05-27T07:57:38.499968Z","shell.execute_reply.started":"2024-05-27T07:36:48.424139Z","shell.execute_reply":"2024-05-27T07:57:38.498955Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [02:05<18:45, 125.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 6.3070     val_loss 5.8164 train_perplexirty 758.6220 val_perplexirty 340.7918\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [04:09<16:39, 124.92s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 5.4720     val_loss 5.4439 train_perplexirty 244.0570 val_perplexirty 235.2224\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [06:14<14:34, 124.92s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 5.0251     val_loss 5.2878 train_perplexirty 155.3410 val_perplexirty 201.6170\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [08:19<12:29, 124.86s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 4.6927     val_loss 5.2322 train_perplexirty 111.1670 val_perplexirty 191.0837\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [10:24<10:24, 124.86s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 4.4245     val_loss 5.2410 train_perplexirty 84.9284 val_perplexirty 193.1412\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [12:29<08:19, 124.95s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 4.1974     val_loss 5.2817 train_perplexirty 67.6328 val_perplexirty 201.5388\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [14:34<06:15, 125.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 3.9985     val_loss 5.3267 train_perplexirty 55.4249 val_perplexirty 211.1879\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [16:39<04:10, 125.09s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 3.8201     val_loss 5.3841 train_perplexirty 46.3572 val_perplexirty 224.0727\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [18:45<02:05, 125.10s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 3.6598     val_loss 5.4538 train_perplexirty 39.4794 val_perplexirty 240.7387\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [20:50<00:00, 125.01s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 3.5142     val_loss 5.5317 train_perplexirty 34.1306 val_perplexirty 260.7878\nBest val perplexirty: 191.083743\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_sequence(model, word2ind, ind2word,starting_seq=nltk.word_tokenize('история россии определяется'))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T07:57:50.529324Z","iopub.execute_input":"2024-05-27T07:57:50.530014Z","iopub.status.idle":"2024-05-27T07:57:50.583780Z","shell.execute_reply.started":"2024-05-27T07:57:50.529983Z","shell.execute_reply":"2024-05-27T07:57:50.582700Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'<bos> история россии определяется населением в россии . <eos>'"},"metadata":{}}]}]}