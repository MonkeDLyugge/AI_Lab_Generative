{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2730445,"sourceType":"datasetVersion","datasetId":1167113}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Подключим необходимые пакеты","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport sqlite3\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport numpy as np\n\nfrom datasets import load_dataset\nfrom nltk.tokenize import sent_tokenize\nfrom sklearn.model_selection import train_test_split\nimport nltk\n\nfrom collections import Counter\nfrom typing import List\nfrom tqdm import tqdm\n\nimport seaborn\nseaborn.set(palette='summer')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:39:59.041271Z","iopub.execute_input":"2024-05-27T05:39:59.041982Z","iopub.status.idle":"2024-05-27T05:40:03.213887Z","shell.execute_reply.started":"2024-05-27T05:39:59.041927Z","shell.execute_reply":"2024-05-27T05:40:03.213115Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:03.215797Z","iopub.execute_input":"2024-05-27T05:40:03.216438Z","iopub.status.idle":"2024-05-27T05:40:03.244527Z","shell.execute_reply.started":"2024-05-27T05:40:03.216405Z","shell.execute_reply":"2024-05-27T05:40:03.243650Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load Data\n\nВ качестве датасета испльзуюся старницы Wiki на русском языке.\nwikibooks-dataset","metadata":{}},{"cell_type":"code","source":"conn = sqlite3.connect('/kaggle/input/wikibooks-dataset/wikibooks.sqlite')\n\ndf = pd.read_sql_query(\"SELECT * FROM ru LIMIT 3300\", conn)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:03.245708Z","iopub.execute_input":"2024-05-27T05:40:03.246047Z","iopub.status.idle":"2024-05-27T05:40:06.488919Z","shell.execute_reply.started":"2024-05-27T05:40:03.246016Z","shell.execute_reply":"2024-05-27T05:40:06.488017Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing data","metadata":{}},{"cell_type":"markdown","source":"Разобьём страницы на тексты длиной 256 символов","metadata":{}},{"cell_type":"code","source":"sentences = []\n\nfor sentence in tqdm(df['body_text']):\n    sentences.extend(\n        [x.lower() for x in sent_tokenize(sentence, language='russian') if len(x) < 256]\n        )\n    \nprint(\"Количество предложений\", len(sentences))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:06.491418Z","iopub.execute_input":"2024-05-27T05:40:06.491765Z","iopub.status.idle":"2024-05-27T05:40:16.817907Z","shell.execute_reply.started":"2024-05-27T05:40:06.491736Z","shell.execute_reply":"2024-05-27T05:40:16.817019Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 3300/3300 [00:10<00:00, 319.92it/s]","output_type":"stream"},{"name":"stdout","text":"Количество предложений 120873\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Посимвольная токенизация","metadata":{}},{"cell_type":"markdown","source":"Определим словарь символов, так же исключим нежелательные символы","metadata":{}},{"cell_type":"code","source":"stop_chars = [\"\\t\", \",\", \".\", \"!\", \"@\", \"'\", '\"', \";\", \"\\n\", \"(\", \")\",\n             \"[\", \"]\", \"{\", \"}\", \"?\", \":\", \"-\", \"_\", \"+\", \"=\", \"^\", \"*\", \n              \"&\", \"`\", \"~\"]\n\nchars = Counter()\n\nfor sentence in tqdm(sentences):\n    for char in sentence:\n        if char in stop_chars:\n            continue\n        chars[char] += 1\n        \nvocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\ncounter_threshold = 500\n\nfor char, cnt in chars.items():\n    if cnt > counter_threshold:\n        vocab.add(char)\n        \nprint(\"Размер словаря:\", len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:16.819042Z","iopub.execute_input":"2024-05-27T05:40:16.819319Z","iopub.status.idle":"2024-05-27T05:40:25.654861Z","shell.execute_reply.started":"2024-05-27T05:40:16.819296Z","shell.execute_reply":"2024-05-27T05:40:25.654001Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 120873/120873 [00:08<00:00, 13696.57it/s]","output_type":"stream"},{"name":"stdout","text":"Размер словаря: 91\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"char2ind = {char: i for i, char in enumerate(vocab)}\nind2char = {i: char for char, i in char2ind.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.656075Z","iopub.execute_input":"2024-05-27T05:40:25.656357Z","iopub.status.idle":"2024-05-27T05:40:25.661202Z","shell.execute_reply.started":"2024-05-27T05:40:25.656334Z","shell.execute_reply":"2024-05-27T05:40:25.660198Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Определим класс CharDataset для последующей загрузки его в dataloader","metadata":{}},{"cell_type":"code","source":"class CharDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = char2ind['<unk>']\n        self.bos_id = char2ind['<bos>']\n        self.eos_id = char2ind['<eos>']\n        self.pad_id = char2ind['<pad>']\n\n    def __getitem__(self, idx: int) -> List[int]:\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [char2ind.get(char, self.unk_id) for char in self.data[idx]]\n        tokenized_sentence += [self.eos_id]\n\n        return tokenized_sentence\n\n    def __len__(self) -> int:\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.662460Z","iopub.execute_input":"2024-05-27T05:40:25.662793Z","iopub.status.idle":"2024-05-27T05:40:25.673549Z","shell.execute_reply.started":"2024-05-27T05:40:25.662764Z","shell.execute_reply":"2024-05-27T05:40:25.672810Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Определим функцию дополнения предложений до max_seq_len","metadata":{}},{"cell_type":"code","source":"def collate_fn_with_padding(\n    input_batch: List[List[int]], pad_id=char2ind['<pad>']) -> torch.Tensor:\n    seq_lens = [len(x) for x in input_batch]\n    max_seq_len = max(seq_lens)\n\n    new_batch = []\n    for sequence in input_batch:\n        for _ in range(max_seq_len - len(sequence)):\n            sequence.append(pad_id)\n        new_batch.append(sequence)\n\n    sequences = torch.LongTensor(new_batch).to(device)\n\n    new_batch = {\n        'input_ids': sequences[:,:-1],\n        'target_ids': sequences[:,1:]\n    }\n\n    return new_batch","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.674669Z","iopub.execute_input":"2024-05-27T05:40:25.675140Z","iopub.status.idle":"2024-05-27T05:40:25.687892Z","shell.execute_reply.started":"2024-05-27T05:40:25.675116Z","shell.execute_reply":"2024-05-27T05:40:25.687011Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Создадим dataloader для train и eval датасетов","metadata":{}},{"cell_type":"code","source":"train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\n\ntrain_dataset = CharDataset(train_sentences)\neval_dataset = CharDataset(eval_sentences)\n\ntrain_dataloader = DataLoader(\n    train_dataset, collate_fn=collate_fn_with_padding, batch_size=256)\n\neval_dataloader = DataLoader(\n    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.690068Z","iopub.execute_input":"2024-05-27T05:40:25.690337Z","iopub.status.idle":"2024-05-27T05:40:25.737037Z","shell.execute_reply.started":"2024-05-27T05:40:25.690305Z","shell.execute_reply":"2024-05-27T05:40:25.736209Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Train loop","metadata":{}},{"cell_type":"code","source":"def fit_epoch(model, train_loader, criterion, optimizer, sheduler = None):\n    model.train()\n    running_loss = 0.0\n    running_corrects = 0\n    processed_data = 0\n    losses = []\n    perplexity = []\n    for batch in train_loader:\n        optimizer.zero_grad()\n\n        logits = model(batch['input_ids']).flatten(start_dim=0, end_dim=1)\n        loss = criterion(\n            logits, batch['target_ids'].flatten())\n        loss.backward()\n        optimizer.step()\n        \n        perplexity.append(torch.exp(loss).item())\n        losses.append(loss.item())\n        \n    perplexity = sum(perplexity) / len(perplexity)\n    losses = sum(losses) / len(losses)    \n    return perplexity, losses","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.741078Z","iopub.execute_input":"2024-05-27T05:40:25.741321Z","iopub.status.idle":"2024-05-27T05:40:25.748097Z","shell.execute_reply.started":"2024-05-27T05:40:25.741300Z","shell.execute_reply":"2024-05-27T05:40:25.747272Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def eval_epoch(model, val_loader, criterion):\n    model.eval()\n    perplexity = []\n    losses = []\n    with torch.no_grad():\n        for batch in val_loader:\n            logits = model(batch['input_ids']).flatten(start_dim=0, end_dim=1)\n            loss = criterion(\n                logits,\n                batch['target_ids'].flatten()\n                )\n            perplexity.append(torch.exp(loss).item())\n            losses.append(loss.item())\n\n    perplexity = sum(perplexity) / len(perplexity)\n    losses = sum(losses) / len(losses)\n    return perplexity, losses","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.749186Z","iopub.execute_input":"2024-05-27T05:40:25.749505Z","iopub.status.idle":"2024-05-27T05:40:25.762628Z","shell.execute_reply.started":"2024-05-27T05:40:25.749477Z","shell.execute_reply":"2024-05-27T05:40:25.761796Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, eval_dataloader, model, epochs, ignore_index = char2ind['<pad>'] ,\n          optimizer=None, criterion=None, sheduler=None):\n\n    if optimizer is None:\n      optimizer = torch.optim.Adam(model.parameters())\n\n    if criterion is None:\n      criterion = nn.CrossEntropyLoss(ignore_index=ignore_index)\n\n    best_model_wts = model.state_dict()\n    best_perplexity = 10e10\n\n    history = []\n    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n    val_loss {v_loss:0.4f} train_perplexirty {t_acc:0.4f} val_perplexirty {v_acc:0.4f}\"\n\n    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n\n        for epoch in range(epochs):\n            train_perplexirty, train_loss = fit_epoch(model, train_dataloader, criterion, optimizer)\n\n            val_perplexirty, val_loss = eval_epoch(model, eval_dataloader, criterion)\n            history.append((train_loss, train_perplexirty, val_loss, val_perplexirty))\n            if val_perplexirty < best_perplexity:\n                best_perplexity = val_perplexirty\n                best_model_wts = model.state_dict()\n\n            pbar_outer.update(1)\n            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n                                           v_loss=val_loss, t_acc=train_perplexirty, v_acc=val_perplexirty))\n\n    print('Best val perplexirty: {:4f}'.format(best_perplexity))\n    model.load_state_dict(best_model_wts)\n\n    return model, history","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:03:44.425275Z","iopub.execute_input":"2024-05-27T06:03:44.425629Z","iopub.status.idle":"2024-05-27T06:03:44.435257Z","shell.execute_reply.started":"2024-05-27T06:03:44.425604Z","shell.execute_reply":"2024-05-27T06:03:44.434467Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Main model","metadata":{}},{"cell_type":"code","source":"class CharLM(nn.Module):\n    def __init__(self, hidden_dim: int, vocab_size: int):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n        self.rnn = nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n        self.linear = nn.Linear(hidden_dim, hidden_dim)\n        self.projection = nn.Linear(hidden_dim, vocab_size)\n\n        self.non_lin = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.1)\n\n    def forward(self, input_batch) -> torch.Tensor:\n        embeddings = self.embedding(input_batch)  # [batch_size, seq_len, hidden_dim]\n        output, _ = self.rnn(embeddings)  # [batch_size, seq_len, hidden_dim]\n        output = self.dropout(self.linear(self.non_lin(output)))  # [batch_size, seq_len, hidden_dim]\n        projection = self.projection(self.non_lin(output))  # [batch_size, seq_len, vocab_size]\n\n        return projection","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.775183Z","iopub.execute_input":"2024-05-27T05:40:25.775729Z","iopub.status.idle":"2024-05-27T05:40:25.787055Z","shell.execute_reply.started":"2024-05-27T05:40:25.775700Z","shell.execute_reply":"2024-05-27T05:40:25.786227Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = CharLM(hidden_dim=256, vocab_size=len(vocab)).to(device)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:25.788043Z","iopub.execute_input":"2024-05-27T05:40:25.788353Z","iopub.status.idle":"2024-05-27T05:40:26.096926Z","shell.execute_reply.started":"2024-05-27T05:40:25.788324Z","shell.execute_reply":"2024-05-27T05:40:26.096019Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"CharLM(\n  (embedding): Embedding(91, 256)\n  (rnn): GRU(256, 256, batch_first=True)\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=91, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.1, inplace=False)\n)\nNumber of model parameters: 507,227\n","output_type":"stream"}]},{"cell_type":"code","source":"model, history = train(train_dataloader, eval_dataloader, model, 10)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:40:26.098023Z","iopub.execute_input":"2024-05-27T05:40:26.098340Z","iopub.status.idle":"2024-05-27T05:46:10.423963Z","shell.execute_reply.started":"2024-05-27T05:40:26.098307Z","shell.execute_reply":"2024-05-27T05:46:10.423024Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [00:35<05:15, 35.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 2.1936     val_loss 1.7596 train_perplexirty 10.3569 val_perplexirty 5.8121\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [01:09<04:36, 34.51s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 1.6882     val_loss 1.6169 train_perplexirty 5.4163 val_perplexirty 5.0392\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [01:43<04:00, 34.33s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 1.5971     val_loss 1.5598 train_perplexirty 4.9411 val_perplexirty 4.7593\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [02:17<03:25, 34.28s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 1.5504     val_loss 1.5254 train_perplexirty 4.7150 val_perplexirty 4.5986\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [02:51<02:51, 34.25s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 1.5201     val_loss 1.5022 train_perplexirty 4.5740 val_perplexirty 4.4928\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [03:25<02:16, 34.21s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 1.4979     val_loss 1.4849 train_perplexirty 4.4738 val_perplexirty 4.4157\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [03:59<01:42, 34.19s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 1.4810     val_loss 1.4726 train_perplexirty 4.3987 val_perplexirty 4.3619\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [04:34<01:08, 34.17s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 1.4678     val_loss 1.4623 train_perplexirty 4.3410 val_perplexirty 4.3171\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [05:08<00:34, 34.15s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 1.4568     val_loss 1.4540 train_perplexirty 4.2933 val_perplexirty 4.2817\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [05:42<00:00, 34.24s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 1.4475     val_loss 1.4468 train_perplexirty 4.2539 val_perplexirty 4.2509\nBest val perplexirty: 4.250897\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Функция для генерации последовательности","metadata":{}},{"cell_type":"code","source":"def generate_sequence(model, dict_2ind ,ind2dict, starting_seq: str, max_seq_len: int = 256) -> str:\n    device = 'cpu'\n    model = model.to(device)\n    input_ids = [dict_2ind['<bos>']] + [\n        dict_2ind.get(char, dict_2ind['<unk>']) for char in starting_seq]\n    input_ids = torch.LongTensor(input_ids).to(device)\n\n    model.eval()\n    with torch.no_grad():\n        for i in range(max_seq_len):\n            next_char_distribution = model(input_ids)[-1]\n            next_char = next_char_distribution.squeeze().argmax()\n            input_ids = torch.cat([input_ids, next_char.unsqueeze(0)])\n\n            if next_char.item() == dict_2ind['<eos>']:\n                break\n\n    words = ' '.join([ind2dict[idx.item()] for idx in input_ids])\n\n    return words","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:25:47.128524Z","iopub.execute_input":"2024-05-27T06:25:47.128970Z","iopub.status.idle":"2024-05-27T06:25:47.139599Z","shell.execute_reply.started":"2024-05-27T06:25:47.128898Z","shell.execute_reply":"2024-05-27T06:25:47.138691Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"generate_sequence(model, char2ind, ind2char, starting_seq='источник ')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:51:29.083040Z","iopub.execute_input":"2024-05-27T05:51:29.083304Z","iopub.status.idle":"2024-05-27T05:51:30.700241Z","shell.execute_reply.started":"2024-05-27T05:51:29.083283Z","shell.execute_reply":"2024-05-27T05:51:30.699340Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'<bos>источник может быть производственные программирования и программирования программирования в программировании в программировании в программировании в программировании в программировании в программировании в программировании в программировании в программировании в пр'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Токенизация по словам","metadata":{}},{"cell_type":"code","source":"import gc\ntorch.cuda.empty_cache()\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:51:58.950765Z","iopub.execute_input":"2024-05-27T05:51:58.951154Z","iopub.status.idle":"2024-05-27T05:51:59.208922Z","shell.execute_reply.started":"2024-05-27T05:51:58.951126Z","shell.execute_reply":"2024-05-27T05:51:59.208008Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"1086"},"metadata":{}}]},{"cell_type":"code","source":"sentences = []\n\nfor sentence in tqdm(df['body_text']):\n    sentences.extend(\n        [x.lower() for x in sent_tokenize(sentence, language='russian') if len(x) < 256]\n        )\n    \nprint(\"Количество предложений\", len(sentences))\n\nwords = Counter()\n\nfor sentence in tqdm(sentences):\n    for word in nltk.word_tokenize(sentence):\n            words[word] += 1\n            \nvocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\nvocab_size = 40000\n\nfor elem in words.most_common(vocab_size):\n    vocab.add(elem[0])\n    \nprint(\"Всего слов в словаре:\", len(vocab))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:52:00.823499Z","iopub.execute_input":"2024-05-27T05:52:00.823855Z","iopub.status.idle":"2024-05-27T05:52:40.365583Z","shell.execute_reply.started":"2024-05-27T05:52:00.823828Z","shell.execute_reply":"2024-05-27T05:52:40.364736Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"100%|██████████| 3300/3300 [00:10<00:00, 319.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Количество предложений 120873\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 120873/120873 [00:29<00:00, 4159.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Всего слов в словаре: 40004\n","output_type":"stream"}]},{"cell_type":"code","source":"word2ind = {char: i for i, char in enumerate(vocab)}\nind2word = {i: char for char, i in word2ind.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:52:42.345901Z","iopub.execute_input":"2024-05-27T05:52:42.346792Z","iopub.status.idle":"2024-05-27T05:52:42.370966Z","shell.execute_reply.started":"2024-05-27T05:52:42.346761Z","shell.execute_reply":"2024-05-27T05:52:42.370017Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class WordDataset:\n    def __init__(self, sentences):\n        self.data = sentences\n        self.unk_id = word2ind['<unk>']\n        self.bos_id = word2ind['<bos>']\n        self.eos_id = word2ind['<eos>']\n        self.pad_id = word2ind['<pad>']\n\n    def __getitem__(self, idx: int) -> List[int]:\n        tokenized_sentence = [self.bos_id]\n        tokenized_sentence += [word2ind.get(word, self.unk_id) for word in nltk.word_tokenize(self.data[idx])]\n        tokenized_sentence += [self.eos_id]\n        \n        return tokenized_sentence\n\n    def __len__(self) -> int:\n        return len(self.data)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:52:45.838575Z","iopub.execute_input":"2024-05-27T05:52:45.839241Z","iopub.status.idle":"2024-05-27T05:52:45.846300Z","shell.execute_reply.started":"2024-05-27T05:52:45.839207Z","shell.execute_reply":"2024-05-27T05:52:45.845307Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def collate_fn_with_padding(\n    input_batch: List[List[int]], pad_id=word2ind['<pad>']) -> torch.Tensor:\n    seq_lens = [len(x) for x in input_batch]\n    max_seq_len = max(seq_lens)\n\n    new_batch = []\n    for sequence in input_batch:\n        for _ in range(max_seq_len - len(sequence)):\n            sequence.append(pad_id)\n        new_batch.append(sequence)\n\n    sequences = torch.LongTensor(new_batch).to(device)\n\n    new_batch = {\n        'input_ids': sequences[:,:-1],\n        'target_ids': sequences[:,1:]\n    }\n\n    return new_batch","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:56:30.941687Z","iopub.execute_input":"2024-05-27T05:56:30.942479Z","iopub.status.idle":"2024-05-27T05:56:30.948993Z","shell.execute_reply.started":"2024-05-27T05:56:30.942451Z","shell.execute_reply":"2024-05-27T05:56:30.948104Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"train_sentences, eval_sentences = train_test_split(sentences, test_size=0.2)\n\ntrain_dataset = WordDataset(train_sentences)\neval_dataset = WordDataset(eval_sentences)\n\ntrain_dataloader = DataLoader(\n    train_dataset, collate_fn=collate_fn_with_padding, batch_size=64,)\n\neval_dataloader = DataLoader(\n    eval_dataset, collate_fn=collate_fn_with_padding, batch_size=64)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:56:31.263627Z","iopub.execute_input":"2024-05-27T05:56:31.264119Z","iopub.status.idle":"2024-05-27T05:56:31.312778Z","shell.execute_reply.started":"2024-05-27T05:56:31.264093Z","shell.execute_reply":"2024-05-27T05:56:31.311962Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"model = CharLM(hidden_dim=256, vocab_size=len(vocab)).to(device)\n\nnum_params = sum(p.numel() for p in model.parameters())\nprint(model)\nprint(f\"Number of model parameters: {num_params:,}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T05:56:56.907809Z","iopub.execute_input":"2024-05-27T05:56:56.908649Z","iopub.status.idle":"2024-05-27T05:56:57.171935Z","shell.execute_reply.started":"2024-05-27T05:56:56.908619Z","shell.execute_reply":"2024-05-27T05:56:57.171022Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"CharLM(\n  (embedding): Embedding(40004, 256)\n  (rnn): GRU(256, 256, batch_first=True)\n  (linear): Linear(in_features=256, out_features=256, bias=True)\n  (projection): Linear(in_features=256, out_features=40004, bias=True)\n  (non_lin): Tanh()\n  (dropout): Dropout(p=0.1, inplace=False)\n)\nNumber of model parameters: 20,982,596\n","output_type":"stream"}]},{"cell_type":"code","source":"best_model, losses = train(train_dataloader, eval_dataloader, model, 10, ignore_index = word2ind[\"<pad>\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:03:48.774603Z","iopub.execute_input":"2024-05-27T06:03:48.775286Z","iopub.status.idle":"2024-05-27T06:21:19.020363Z","shell.execute_reply.started":"2024-05-27T06:03:48.775254Z","shell.execute_reply":"2024-05-27T06:21:19.019472Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"epoch:  10%|█         | 1/10 [01:45<15:45, 105.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 001 train_loss: 4.8116     val_loss 5.2675 train_perplexirty 125.5927 val_perplexirty 198.0715\n","output_type":"stream"},{"name":"stderr","text":"epoch:  20%|██        | 2/10 [03:30<14:00, 105.06s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 002 train_loss: 4.4128     val_loss 5.2255 train_perplexirty 83.7987 val_perplexirty 190.3353\n","output_type":"stream"},{"name":"stderr","text":"epoch:  30%|███       | 3/10 [05:15<12:16, 105.16s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 003 train_loss: 4.1199     val_loss 5.2401 train_perplexirty 62.4511 val_perplexirty 193.5814\n","output_type":"stream"},{"name":"stderr","text":"epoch:  40%|████      | 4/10 [07:00<10:30, 105.16s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 004 train_loss: 3.8801     val_loss 5.2854 train_perplexirty 49.1157 val_perplexirty 203.0046\n","output_type":"stream"},{"name":"stderr","text":"epoch:  50%|█████     | 5/10 [08:45<08:45, 105.08s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 005 train_loss: 3.6778     val_loss 5.3549 train_perplexirty 40.0971 val_perplexirty 218.1294\n","output_type":"stream"},{"name":"stderr","text":"epoch:  60%|██████    | 6/10 [10:30<07:00, 105.04s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 006 train_loss: 3.5041     val_loss 5.4265 train_perplexirty 33.6972 val_perplexirty 234.8418\n","output_type":"stream"},{"name":"stderr","text":"epoch:  70%|███████   | 7/10 [12:15<05:14, 105.00s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 007 train_loss: 3.3560     val_loss 5.5033 train_perplexirty 29.0495 val_perplexirty 254.1279\n","output_type":"stream"},{"name":"stderr","text":"epoch:  80%|████████  | 8/10 [14:00<03:29, 104.98s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 008 train_loss: 3.2282     val_loss 5.5834 train_perplexirty 25.5596 val_perplexirty 275.9186\n","output_type":"stream"},{"name":"stderr","text":"epoch:  90%|█████████ | 9/10 [15:45<01:44, 104.99s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 009 train_loss: 3.1171     val_loss 5.6592 train_perplexirty 22.8660 val_perplexirty 298.2022\n","output_type":"stream"},{"name":"stderr","text":"epoch: 100%|██████████| 10/10 [17:30<00:00, 105.02s/it]","output_type":"stream"},{"name":"stdout","text":"\nEpoch 010 train_loss: 3.0210     val_loss 5.7391 train_perplexirty 20.7655 val_perplexirty 323.7256\nBest val perplexirty: 190.335309\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"generate_sequence(model, word2ind, ind2word, starting_seq=nltk.word_tokenize('кот'))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T06:27:51.197592Z","iopub.execute_input":"2024-05-27T06:27:51.198159Z","iopub.status.idle":"2024-05-27T06:27:51.296002Z","shell.execute_reply.started":"2024-05-27T06:27:51.198129Z","shell.execute_reply":"2024-05-27T06:27:51.295026Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"'<bos> кот высотой 2 марта 2008 года выборы президента российской федерации выборы уважаемый избиратель ! <eos>'"},"metadata":{}}]}]}